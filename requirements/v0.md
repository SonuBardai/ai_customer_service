## **Project Details**

**Build a platform that enables companies to create and deploy AI customer support chatbots on their own websites, via a simple script integration.**

---

## **Task Overview**

Develop a web-based dashboard where companies can:

* Sign up and manage their account  
* Configure a custom AI chatbot agent by:
  * Uploading or entering support instructions / knowledge base content (markdown, text, URLs, or FAQ entries)
  * Setting tone/personality preferences (e.g., formal, friendly, humorous)
  * Defining key intents or special-case instructions (e.g., escalate billing issues, avoid legal advice)  
* Generate an embeddable script (like Intercom or Drift) to add the chatbot widget to their marketing site  
* View analytics and conversation logs with optional feedback (e.g., thumbs up/down, comments)

The embedded chatbot should:

* Be branded to match the company’s color scheme and logo  
* Answer customer queries using only the company-provided knowledge base and instructions  
* Escalate to human support or email capture when it cannot answer  
* Respond in real-time with minimal latency  
* Support multi-turn conversations with context awareness

---

## **Performance Requirements**

* Embeddable widget must load fast (target: < 1s) and work on all major modern browsers  
* AI agent should respond to most queries in under 2 seconds  
* Dashboard must support simultaneous access by multiple users in a company (multi-tenant architecture)  
* Handle high-concurrency scenarios (e.g., 1000+ simultaneous users across different embedded instances)

---

## **Edge Cases**

* How will the AI be constrained to only use the client’s instructions and avoid hallucinations?  
* How do you handle follow-up queries when the original context may not be clear (e.g., ambiguous pronouns)?  
* How will fallback or escalation work when the AI is unsure (e.g., connect to live chat, email form)?  
* How will chatbot behavior be updated after changes to instructions — is there a versioning system or delay?  
* How do you ensure the AI behaves differently for different clients, even when deployed on the same server?

---

## **Evaluation Criteria**

### **Code Quality and Architecture**

* Modular and maintainable codebase with clear boundaries between dashboard, agent logic, and embed client  
* Secure multi-tenant design to isolate client data and ensure safe sandboxed chatbot responses  
* Use of modern frameworks and best practices for scalability (e.g., React for frontend, NoSQL + Django backend)

### **Latency Optimization**

* Embedding script should be lightweight and lazy-load resources after page load  
* Use streaming or partial response techniques (e.g., via OpenAI function calling, streaming APIs) for fast AI replies  
* Caching strategies for common questions to avoid repeated processing

### **AI Accuracy and Control**

* Fine-tuning prompts or retrieval techniques (RAG) to improve grounding in company-provided knowledge  
* Testing and evaluation of AI hallucination risk  
* Mechanism for human feedback loop and continuous improvement of agent performance

### **User Experience**

* Simple and clean UI for both admin dashboard and chat widget  
* Easy onboarding for new companies with helpful defaults and templates  
* Real-time logs and analytics with filters (e.g., most common questions, failure rate)  
* Controls for admins to preview chatbot behavior before deployment

### **Security and Abuse Prevention**

The system must implement robust safeguards against misuse, especially since the chatbot will be publicly embedded on external marketing pages:

* **Rate Limiting**  
  * Each chatbot instance must enforce per-IP rate limits (e.g., max requests/minute)  
  * Add exponential backoff or CAPTCHA for excessive activity from a single IP  

* **Origin Verification**  
  * Embedded widgets must only work when loaded from whitelisted domains specified by the customer  
  * Use signed embed tokens that expire and validate customer identity  

* **Prompt Injection Mitigation**  
  * Sanitize and preprocess user messages to reduce risk of prompt injection  
  * Separate user inputs from system instructions in model prompts (e.g., using structured function calling or RAG)

* **Data Isolation**  
  * Multi-tenant backend must guarantee strict isolation of customer data and knowledge bases  
  * All logs, chat history, and analytics should be scoped to each company’s tenant ID  

* **Audit and Monitoring**  
  * Track abuse patterns and log suspicious activity  
  * Optional logging of user IPs and behavior for rate-limiting and forensic purposes  

### **Third-Party Integrations**

The dashboard should offer plug-and-play integrations with popular tools to enhance the chatbot's usefulness and create alert/response workflows. Initial integrations:

* **Slack**  
  * Send escalated chats or alerts (e.g., “AI could not resolve X question”) to a specific Slack channel  
  * Allow admins to configure escalation triggers and recipient channels per bot instance

* **Notion**  
  * Log structured summaries of unresolved queries or user feedback to a Notion database  
  * Optionally allow importing company documentation from Notion pages as part of chatbot knowledge base

* **Zapier / Webhooks**  
  * Generic integration method for sending structured event notifications (e.g., new lead captured, failed intent, feedback submitted)  
  * Support custom payloads and retry mechanisms

*Future integrations may include:*
* Intercom or Zendesk (for hybrid AI-human handoff)
* Google Sheets or Airtable (for lightweight CRM)
* Email alerts (SMTP or third-party API)

---

## **Stretch Goals**

* Support for multilingual customer support (detect and respond in user’s language)  
* Integration with CRM tools (e.g., HubSpot, Salesforce)  
* GPT fine-tuning or embeddings upload for more advanced clients  
* Export conversation data and usage analytics as CSV or via API  

---
